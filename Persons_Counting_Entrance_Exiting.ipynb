{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "# $ Entering - Exiting \\space  Persons\\space  Counting \\space using $\n",
        "# *``YOLOv8 \\ YOLOv10``*  $\\&$  *``Roboflow Supervision``*\n",
        "\n",
        "Â© Nassim Hammemi, 2024. All rights reserved.\n",
        "\n",
        "This notebook is licensed under the [MIT License](https://opensource.org/licenses/MIT). You may use, distribute, and modify this code under the terms of the license.\n",
        "\n",
        "---\n",
        "\n",
        "<a align=\"\">\n",
        "  <img width=\"1900\"src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\">\n",
        "</a>\n",
        "\n",
        "<a align=\"\">\n",
        "\n",
        "\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "djuWUvCKiD_S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZIxqXT9Uwv9"
      },
      "source": [
        "# $Setup$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0yDHlNYqSF-"
      },
      "source": [
        "Install `ultralytics` to Download, Train, Test, and Export Object detection models.\n",
        "\n",
        "<a align=\"center\">\n",
        "  <img width=\"200\" src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS3UZ_6GUwv9"
      },
      "outputs": [],
      "source": [
        "%pip install ultralytics  # install\n",
        "from IPython import display\n",
        "display.clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjPvSUaPUwv9"
      },
      "source": [
        "Install `roboflow` for datasets downloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ_wF1K3Uwv-"
      },
      "outputs": [],
      "source": [
        "%pip install roboflow\n",
        "display.clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f65K9sFKUwv-",
        "outputId": "bebb0ac7-615a-4cf4-8ec9-54445db7d8b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.188 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.5/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import yaml\n",
        "from roboflow import Roboflow\n",
        "from ultralytics import YOLO, checks, hub\n",
        "checks()  # checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utKPQ-uppf6A"
      },
      "source": [
        "## Install Supervision\n",
        "\n",
        "<a align=\"center\">\n",
        "  <img width =\"300\" src=\"https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_c-zG0RtUwv_"
      },
      "outputs": [],
      "source": [
        "!pip install supervision==0.1.0\n",
        "display.clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "891hAnvPUwv_"
      },
      "source": [
        "## Install ByteTrack\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqJnEO2dUwv_",
        "outputId": "960814f2-ef6c-4290-fbf7-c1f91a57025c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d09yO8k8Uwv_"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "%cd {HOME}/ByteTrack\n",
        "\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/80\n",
        "!sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
        "\n",
        "!pip3 install -q -r requirements.txt\n",
        "!python3 setup.py -q develop\n",
        "!pip install -q cython_bbox\n",
        "!pip install -q onemetric\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/112\n",
        "!pip install -q loguru lap\n",
        "\n",
        "display.clear_output()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "loLizlD2Uwv_"
      },
      "outputs": [],
      "source": [
        "!pip3 install thop\n",
        "display.clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpqpKsM0Uwv_",
        "outputId": "3f7b8b23-88b3-4957-a220-fa54f05970c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "yolox.__version__: 0.1.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")\n",
        "import yolox\n",
        "print(\"yolox.__version__:\", yolox.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6sYGIhKkUwwA"
      },
      "outputs": [],
      "source": [
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CwO0IE2VUwwA"
      },
      "outputs": [],
      "source": [
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSdi_e1-UwwA"
      },
      "source": [
        "## Tracking utils\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Dv7jOfiBUwwA"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: Detections) -> np.ndarray:\n",
        "    return np.hstack((\n",
        "        detections.xyxy,\n",
        "        detections.confidence[:, np.newaxis]\n",
        "    ))\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: Detections,\n",
        "    tracks: List[STrack]\n",
        ") -> Detections:\n",
        "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
        "        return np.empty((0,))\n",
        "\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "\n",
        "    tracker_ids = [None] * len(detections)\n",
        "\n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
        "\n",
        "    return tracker_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWi3qUSQeKkX"
      },
      "source": [
        "#$YOLO_v8-Model-path$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_sY0jIHeiEt",
        "outputId": "14956091-4954-4787-e031-cd7099798d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48907a63-0dfb-44ae-b4dd-0d2eae9f8c5d",
        "id": "f6MgsiI7cbbO"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt to yolov8x.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131M/131M [00:11<00:00, 11.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"path\\best.pt\")  # load a pretrained model (recommended for training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il9Z78FDxMxT"
      },
      "source": [
        "# $Tracking \\space \\& \\space Counting$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02MaNdbHN8LF",
        "outputId": "caa23f80-1b7b-49a1-ce74-5b4bbb7fca8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VideoInfo(width=3840, height=2160, fps=24, total_frames=387)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SOURCE_VIDEO_PATH='/content/pexels-kelly-3736783-3840x2160-24fps.mp4'\n",
        "\n",
        "VideoInfo.from_video_path(SOURCE_VIDEO_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aEuP8gCpNMx"
      },
      "outputs": [],
      "source": [
        "# settings\n",
        "LINE_START = Point(1000, 0)\n",
        "LINE_END = Point(1000, 2160)\n",
        "\n",
        "TARGET_VIDEO_PATH = f\"{HOME}/result.mp4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zFj8uXo7dwD"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCC4JR6BSAaI"
      },
      "outputs": [],
      "source": [
        "# dict maping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "# class_ids of interest - car, motorcycle, bus and truck\n",
        "CLASS_ID = [i for i in range(80)]\n",
        "print(CLASS_NAMES_DICT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ktUPbNnAY2S"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# create BYTETracker instance\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "# create VideoInfo instance\n",
        "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "# create frame generator\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "# create LineCounter instance\n",
        "line_counter = LineCounter(start=LINE_START, end=LINE_END)\n",
        "# create instance of BoxAnnotator and LineCounterAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette.default(), thickness=4, text_thickness=4, text_scale=2)\n",
        "line_annotator = LineCounterAnnotator(thickness=2, text_thickness=2, text_scale=2)\n",
        "\n",
        "# open target video file\n",
        "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
        "    # loop over video frames\n",
        "    for frame in tqdm(generator, total=video_info.total_frames):\n",
        "        # model prediction on single frame and conversion to supervision Detections\n",
        "        results = model(frame,classes=[0])\n",
        "        detections = Detections(\n",
        "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "        )\n",
        "        # filtering out detections with unwanted classes\n",
        "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # tracking detections\n",
        "        tracks = byte_tracker.update(\n",
        "            output_results=detections2boxes(detections=detections),\n",
        "            img_info=frame.shape,\n",
        "            img_size=frame.shape\n",
        "        )\n",
        "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
        "        detections.tracker_id = np.array(tracker_id)\n",
        "        # filtering out detections without trackers\n",
        "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # format custom labels\n",
        "        labels = [\n",
        "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "            for _, confidence, class_id, tracker_id\n",
        "            in detections\n",
        "        ]\n",
        "        # updating line counter\n",
        "        line_counter.update(detections=detections)\n",
        "        # annotate and display frame\n",
        "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "        line_annotator.annotate(frame=frame, line_counter=line_counter)\n",
        "        sink.write_frame(frame)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "JZIxqXT9Uwv9",
        "utKPQ-uppf6A",
        "XWi3qUSQeKkX",
        "il9Z78FDxMxT"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}